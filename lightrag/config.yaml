# LightRAG Configuration
# This configuration file is used by the LightRAG service

# Server configuration
server:
  host: "0.0.0.0"
  port: 9621

# LLM configuration
llm:
  # OpenAI configuration (if using OpenAI)
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-mini"
    temperature: 0.7
  
  # Anthropic configuration (if using Anthropic)
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-haiku-20240307"
    temperature: 0.7
  
  # Ollama configuration (if using local Ollama)
  ollama:
    base_url: "${OLLAMA_BASE_URL:-http://ollama:11434}"
    model: "qwen2.5:7b-instruct-q4_K_M"
    temperature: 0.7

# Vector database configuration
vector_db:
  # Qdrant configuration
  qdrant:
    url: "http://qdrant:6333"
    api_key: "${QDRANT_API_KEY}"
    collection_name: "lightrag"
  
  # Alternative: Weaviate configuration
  weaviate:
    url: "http://weaviate:8080"
    api_key: "${WEAVIATE_API_KEY}"
    class_name: "LightRAG"

# Graph database configuration
graph_db:
  # Neo4j configuration
  neo4j:
    uri: "bolt://neo4j:7687"
    username: "${NEO4J_AUTH_USERNAME:-neo4j}"
    password: "${NEO4J_AUTH_PASSWORD}"

# Storage configuration
storage:
  data_dir: "/app/data"
  shared_dir: "/data/shared"

# Logging configuration
logging:
  level: "INFO"
  format: "json"

# API configuration
api:
  enable_cors: true
  max_request_size: "10MB"
  timeout: 300

# Health check configuration
health:
  enabled: true
  path: "/health"
  interval: 30

